{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow 2.x\n",
        "!pip install -q tensorflow\n",
        "\n",
        "# Imports\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D,\n",
        "    Add, Dense, Input\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n"
      ],
      "metadata": {
        "id": "xHJUfg42FubR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Constants\n",
        "WINDOW_SIZE = 60\n",
        "NUM_FEATURES = 6\n",
        "STRIDE = 15\n",
        "ACCURACY_CUTOFF = 0.95\n",
        "EPOCHS = 100\n",
        "\n",
        "# Project Paths\n",
        "PROJECT_DIR = Path(\"/content/drive/MyDrive/Colab_HAR_Project\")\n",
        "DATA_DIR = PROJECT_DIR / \"data\"\n",
        "OUTPUT_DIR = PROJECT_DIR / \"converted_test_model\"\n",
        "MODEL_SAVE_PATH = OUTPUT_DIR / \"trained_tcn_model.h5\"\n",
        "SAVED_MODEL_DIR = str(OUTPUT_DIR / \"fl_model_saved\")\n",
        "\n",
        "# Ensure output directory exists\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "GoKyK9asJOE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0Dksa-nzYGQ"
      },
      "outputs": [],
      "source": [
        "def create_windows(df, window_size, stride):\n",
        "    windows, labels = [], []\n",
        "    if 'subject' not in df.columns:\n",
        "        df['subject'] = 'default'\n",
        "    for _, group_df in df.groupby(['subject', 'activity']):\n",
        "        data = group_df[['x_accel', 'y_accel', 'z_accel', 'x_gyro', 'y_gyro', 'z_gyro']].values\n",
        "        if len(data) < window_size:\n",
        "            continue\n",
        "        for start in range(0, len(data) - window_size + 1, stride):\n",
        "            windows.append(data[start:start + window_size])\n",
        "            labels.append(group_df[\"activity\"].iloc[0])\n",
        "    return np.array(windows, dtype=np.float32), np.array(labels)\n",
        "\n",
        "\n",
        "def build_tcn_model(input_shape, num_classes):\n",
        "    x = input_layer = Input(shape=input_shape)\n",
        "    for rate in [1, 2, 4, 8, 16]:\n",
        "        prev_x = x\n",
        "        x = Conv1D(64, 7, dilation_rate=rate, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        if prev_x.shape[-1] != x.shape[-1]:\n",
        "            prev_x = Conv1D(64, 1, padding='same')(prev_x)\n",
        "        x = Add()([prev_x, x])\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(DATA_DIR / \"resampled_normalized_phone_data.csv\")\n",
        "df2 = pd.read_csv(DATA_DIR / \"combined_collected_data.csv\")\n",
        "\n",
        "combined_df = pd.concat([\n",
        "    df1[df1['activity'].isin(['B', 'D', 'E'])],\n",
        "    df2[df2['activity'].isin(['A', 'C'])]\n",
        "], ignore_index=True)\n",
        "\n",
        "X, y_raw = create_windows(combined_df, WINDOW_SIZE, STRIDE)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw).astype(np.int32)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, NUM_FEATURES)).reshape(X_train.shape)\n",
        "X_val_scaled = scaler.transform(X_val.reshape(-1, NUM_FEATURES)).reshape(X_val.shape)\n",
        "\n",
        "model = build_tcn_model((WINDOW_SIZE, NUM_FEATURES), num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "class EarlyStoppingByAccuracy(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, target_acc=ACCURACY_CUTOFF):\n",
        "        super().__init__()\n",
        "        self.target_acc = target_acc\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_acc = logs.get(\"val_accuracy\")\n",
        "        if val_acc and val_acc >= self.target_acc:\n",
        "            print(f\"✅ Early stop: val_accuracy={val_acc:.4f} ≥ {self.target_acc}\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=64,\n",
        "    verbose=2,\n",
        "    callbacks=[EarlyStoppingByAccuracy()]\n",
        ")\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"✅ Model saved at: {MODEL_SAVE_PATH}\")\n"
      ],
      "metadata": {
        "id": "iZP-UN7n5NCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8115065-73fc-40be-9098-802842c9cc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "✅ Early stop: val_accuracy=0.9558 ≥ 0.95\n",
            "702/702 - 110s - 157ms/step - accuracy: 0.9377 - loss: 0.1696 - val_accuracy: 0.9558 - val_loss: 0.1085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved at: /content/drive/MyDrive/Colab_HAR_Project/converted_test_model/trained_tcn_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FederatedModelWrapper(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.optimizer = tf.keras.optimizers.Adam()\n",
        "        self.weight_specs = [\n",
        "            tf.TensorSpec(shape=w.shape, dtype=w.dtype) for w in model.trainable_variables\n",
        "        ]\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec([None, WINDOW_SIZE, NUM_FEATURES], tf.float32),\n",
        "        tf.TensorSpec([None], tf.int32)\n",
        "    ])\n",
        "    def train(self, x, y):\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self.model(x, training=True)\n",
        "            loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y, preds))\n",
        "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds, axis=1, output_type=tf.int32), y), tf.float32))\n",
        "        return {\"loss\": loss, \"accuracy\": acc}\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec([None, WINDOW_SIZE, NUM_FEATURES], tf.float32)])\n",
        "    def infer(self, x):\n",
        "        return {\"predictions\": self.model(x, training=False)}\n",
        "\n",
        "    @tf.function(input_signature=[])\n",
        "    def get_weights(self):\n",
        "        return {f'w{i}': w for i, w in enumerate(self.model.trainable_variables)}\n",
        "\n",
        "    @tf.function\n",
        "    def set_weights(self, *weights):\n",
        "        for var, val in zip(self.model.trainable_variables, weights):\n",
        "            var.assign(val)\n",
        "        return {\"status\": tf.constant(\"weights_set\")}\n",
        "\n",
        "    def get_signatures(self):\n",
        "        return {\n",
        "            \"train\": self.train.get_concrete_function(),\n",
        "            \"infer\": self.infer.get_concrete_function(),\n",
        "            \"get_weights\": self.get_weights.get_concrete_function(),\n",
        "            \"set_weights\": self.set_weights.get_concrete_function(*self.weight_specs),\n",
        "        }\n",
        "\n",
        "# Load if needed\n",
        "if model is None:\n",
        "    model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "fl_model = FederatedModelWrapper(model)\n",
        "tf.saved_model.save(fl_model, SAVED_MODEL_DIR, signatures=fl_model.get_signatures())\n",
        "print(\"✅ SavedModel exported:\", SAVED_MODEL_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgzJTX_NJdCH",
        "outputId": "53f16d21-0037-4484-8a44-6a3064a4b8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SavedModel exported: /content/drive/MyDrive/Colab_HAR_Project/converted_test_model/fl_model_saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_enable_resource_variables = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_path = OUTPUT_DIR / \"fl_tcn_model.tflite\"\n",
        "with open(tflite_path, \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"✅ TFLite model exported to:\", tflite_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyMLMxqrLo6R",
        "outputId": "7474f753-e4b5-470f-b626-b586ecc85e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_65689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_65836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_65689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_65836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TFLite model exported to: /content/drive/MyDrive/Colab_HAR_Project/converted_test_model/fl_tcn_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Create output directory\n",
        "output_dir = PROJECT_DIR / \"converted_test_model\"\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Run predictions\n",
        "X_test = X_val_scaled[:32]\n",
        "y_test = y_val[:32]\n",
        "preds_before = model.predict(X_test)\n",
        "\n",
        "# Save original weights\n",
        "orig_weights = [w.numpy() for w in model.trainable_variables]\n",
        "\n",
        "# Run a federated training step\n",
        "train_result = fl_model.train(X_test, y_test)\n",
        "\n",
        "# Predict after training\n",
        "preds_after = model.predict(X_test)\n",
        "\n",
        "# Save test data and predictions (NPY)\n",
        "np.save(output_dir / \"X_test.npy\", X_test)\n",
        "np.save(output_dir / \"y_test.npy\", y_test)\n",
        "np.save(output_dir / \"preds_before.npy\", preds_before)\n",
        "np.save(output_dir / \"preds_after.npy\", preds_after)\n",
        "np.save(output_dir / \"orig_weights.npy\", np.array(orig_weights, dtype=object), allow_pickle=True)\n",
        "\n",
        "# Save as CSV for inspection\n",
        "np.savetxt(output_dir / \"X_test.csv\", X_test.reshape(X_test.shape[0], -1), delimiter=\",\")\n",
        "np.savetxt(output_dir / \"y_test.csv\", y_test, fmt=\"%d\", delimiter=\",\")\n",
        "\n",
        "print(\"✅ All outputs saved to:\", output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmLLI_-jMH3d",
        "outputId": "df406814-c6fa-4857-c94d-7a37eaec1906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "✅ All outputs saved to: /content/drive/MyDrive/Colab_HAR_Project/converted_test_model\n"
          ]
        }
      ]
    }
  ]
}