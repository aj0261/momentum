{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6-sMC855E7H",
        "outputId": "bda693ce-0994-49cb-e2c9-a7199850506e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Block 1: Setup and Configuration ---\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "All new assets will be saved to: /content/drive/MyDrive/Colab_HAR_Project/results/TCN_Results_v2_with_Assets/Converted_Assets\n",
            "\n",
            "--- Block 2: Load Data and Reconstruct Assets from JSON ---\n",
            "Label Encoder reconstructed. Classes: [np.str_('A'), np.str_('B'), np.str_('C'), np.str_('D'), np.str_('E')]\n",
            "Scaler object reconstructed from JSON file.\n",
            "Data types corrected. X_test_scaled dtype is now: float32\n",
            "Keras model loaded successfully.\n",
            "\n",
            "--- Block 3: TFLite Model Conversions ---\n",
            "  [1/2] Converting to INT8...\n",
            "Saved artifact at '/tmp/tmph8ladoam'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60, 6), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138991927626064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927624912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927624720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927624336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927625680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927629136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927623760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927628560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927632592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927629904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927631056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927633360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927632208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927632976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927631248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927631824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927634320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927636048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927634128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927630096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927634896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927633936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927635856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927637008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927636624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927630672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927637968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927633168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927638544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927638928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991924152080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927639888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927635472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991924150928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991931538128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138992183512144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741856528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138992183520592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138992183519632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741857680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741854224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741859792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741858448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741859408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741855184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741860752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741860368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741855760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741854800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741854608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741858640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741861328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741853648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575467024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575466256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741857488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575466448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575467984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575469712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  INT8 model saved successfully.\n",
            "  [2/2] Converting to Float16...\n",
            "Saved artifact at '/tmp/tmptnmw2cg_'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60, 6), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138991927626064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927624912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927624720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927624336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927625680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927629136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927623760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927628560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927632592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927629904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927627408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927631056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927633360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927632208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927632976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927631248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927631824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927634320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927636048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927634128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927630096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927634896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927633936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927635856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927637008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927636624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927630672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927637968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927633168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927638544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927638928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991924152080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927639888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991927635472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991924150928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991931538128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138992183512144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741856528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138992183520592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138992183519632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741857680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741854224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741859792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741858448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741859408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741855184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741860752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741860368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741855760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741854800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741854608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741858640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741861328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741853648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575467024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575466256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991741857488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575466448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575467984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138991575469712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  Float16 model saved successfully.\n",
            "  JSON assets copied to the new directory.\n",
            "\n",
            "--- Block 4: Benchmarking and Final Report ---\n",
            "  Benchmarking Keras model...\n",
            "  Benchmarking TFLite INT8 model...\n",
            "  Benchmarking TFLite Float16 model...\n",
            "\n",
            "======================================================================\n",
            "             MODEL OPTIMIZATION AND BENCHMARK REPORT\n",
            "======================================================================\n",
            "      Model Type Accuracy Avg. Latency (ms) Size (KB)\n",
            " Keras (Float32)   0.9953            83.591    3290.1\n",
            "   TFLite (INT8)   0.9542             0.537     300.8\n",
            "TFLite (Float16)   0.9953             0.422     541.0\n",
            "======================================================================\n",
            "\n",
            "Recommendation:\n",
            "✅ The Float16 model is the recommended choice. It significantly improves accuracy over INT8, making it worth the slight size/speed trade-off.\n",
            "\n",
            "Final deployable assets are located in:\n",
            "/content/drive/MyDrive/Colab_HAR_Project/results/TCN_Results_v2_with_Assets/Converted_Assets\n",
            "total 844K\n",
            "-rw------- 1 root root 542K Jul 15 04:31 har_model_float16.tflite\n",
            "-rw------- 1 root root 301K Jul 15 04:31 har_model_int8.tflite\n",
            "-rw------- 1 root root   72 Jul 15 04:31 labels.json\n",
            "-rw------- 1 root root  384 Jul 15 04:31 scaler.json\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Colab Notebook: Model Optimization and Benchmarking\n",
        "#\n",
        "# This script takes a pre-trained Keras model and its corresponding assets,\n",
        "# then creates and benchmarks optimized TFLite versions (INT8 and Float16)\n",
        "# for Android deployment.\n",
        "#\n",
        "# It is designed to run AFTER 'TCNonOwnData_v2.ipynb' has completed.\n",
        "#\n",
        "# Workflow:\n",
        "# 1. Load the Keras model and reconstruct scaler/encoder from JSON files.\n",
        "# 2. Re-create the exact same data splits for fair evaluation.\n",
        "# 3. Convert the model to a highly-optimized INT8 TFLite model.\n",
        "# 4. Convert the model to a high-accuracy Float16 TFLite model.\n",
        "# 5. Save all new TFLite models and a copy of the JSONs to a new\n",
        "#    'Converted_Assets' subdirectory.\n",
        "# 6. Run a comprehensive benchmark measuring accuracy, latency, and size\n",
        "#    for all three model versions (Keras, INT8, Float16).\n",
        "# 7. Provide a final recommendation based on the results.\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Block 1: Setup and Configuration ---\n",
        "print(\"--- Block 1: Setup and Configuration ---\")\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Path Configuration ---\n",
        "# 1. Point to the results directory from your V2 training script\n",
        "BASE_RESULTS_DIR = Path('/content/drive/MyDrive/Colab_HAR_Project/results/TCN_Results_v2_with_Assets')\n",
        "FILE_PREFIX = \"tcn_v2_ABCDE_\"\n",
        "\n",
        "# 2. Define the new subdirectory for our converted assets\n",
        "CONVERTED_ASSETS_DIR = BASE_RESULTS_DIR / 'Converted_Assets'\n",
        "CONVERTED_ASSETS_DIR.mkdir(parents=True, exist_ok=True) # Create it\n",
        "print(f\"All new assets will be saved to: {CONVERTED_ASSETS_DIR}\")\n",
        "\n",
        "# 3. Define paths to SOURCE assets (from the training run)\n",
        "KERAS_MODEL_PATH = BASE_RESULTS_DIR / f'{FILE_PREFIX}har_model.keras'\n",
        "SCALER_PATH_JSON_SRC = BASE_RESULTS_DIR / f'{FILE_PREFIX}scaler.json'\n",
        "LABELS_PATH_JSON_SRC = BASE_RESULTS_DIR / f'{FILE_PREFIX}labels.json'\n",
        "\n",
        "# 4. Define paths for the new DESTINATION assets\n",
        "TFLITE_INT8_PATH_DEST = CONVERTED_ASSETS_DIR / 'har_model_int8.tflite'\n",
        "TFLITE_FLOAT16_PATH_DEST = CONVERTED_ASSETS_DIR / 'har_model_float16.tflite'\n",
        "SCALER_PATH_JSON_DEST = CONVERTED_ASSETS_DIR / 'scaler.json'\n",
        "LABELS_PATH_JSON_DEST = CONVERTED_ASSETS_DIR / 'labels.json'\n",
        "\n",
        "# ==============================================================================\n",
        "# Block 2: Load Data and Reconstruct Assets from JSON (Corrected and Final)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Block 2: Load Data and Reconstruct Assets from JSON ---\")\n",
        "\n",
        "# --- Function to recreate data windows (copied from training script) ---\n",
        "def create_subject_activity_windows(df, window_size, stride):\n",
        "    windows, labels = [], []\n",
        "    required_cols = ['x_accel', 'y_accel', 'z_accel', 'x_gyro', 'y_gyro', 'z_gyro']\n",
        "    for _, group_df in df.groupby(['subject', 'activity']):\n",
        "        data_values = group_df.sort_values('timestamp')[required_cols].values\n",
        "        if len(data_values) < window_size: continue\n",
        "        for start in range(0, len(data_values) - window_size + 1, stride):\n",
        "            windows.append(data_values[start : start + window_size])\n",
        "            labels.append(group_df[\"activity\"].iloc[0])\n",
        "    return np.array(windows), np.array(labels)\n",
        "\n",
        "# --- Recreate the exact same Train/Test split ---\n",
        "input_data_path = Path('/content/drive/MyDrive/Colab_HAR_Project/data')\n",
        "df1 = pd.read_csv(input_data_path / 'resampled_normalized_phone_data.csv')\n",
        "df2 = pd.read_csv(input_data_path / 'combined_collected_data.csv')\n",
        "df1_f = df1[df1['activity'].isin(['B', 'D', 'E'])]\n",
        "df2_f = df2[df2['activity'].isin(['A', 'C'])]\n",
        "combined_df = pd.concat([df1_f, df2_f], ignore_index=True)\n",
        "\n",
        "X, y_raw = create_subject_activity_windows(combined_df, 60, 15)\n",
        "\n",
        "# --- Reconstruct LabelEncoder and Scaler from their JSON files ---\n",
        "with open(LABELS_PATH_JSON_SRC) as f:\n",
        "    labels_dict = json.load(f)\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.array(list(labels_dict.values()))\n",
        "y = label_encoder.transform(y_raw)\n",
        "print(f\"Label Encoder reconstructed. Classes: {list(label_encoder.classes_)}\")\n",
        "\n",
        "with open(SCALER_PATH_JSON_SRC) as f:\n",
        "    scaler_params = json.load(f)\n",
        "scaler = StandardScaler()\n",
        "scaler.mean_ = np.array(scaler_params['mean'])\n",
        "scaler.scale_ = np.array(scaler_params['scale'])\n",
        "print(\"Scaler object reconstructed from JSON file.\")\n",
        "\n",
        "# --- Perform the consistent data split and scaling ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "X_train_scaled = scaler.transform(X_train.reshape(-1, 6)).reshape(X_train.shape)\n",
        "X_test_scaled = scaler.transform(X_test.reshape(-1, 6)).reshape(X_test.shape)\n",
        "\n",
        "# ==============================================================================\n",
        "# --- THE FIX IS HERE ---\n",
        "# Explicitly cast the scaled data to float32 to match TensorFlow's expectations.\n",
        "X_train_scaled = X_train_scaled.astype(np.float32)\n",
        "X_test_scaled = X_test_scaled.astype(np.float32)\n",
        "print(f\"Data types corrected. X_test_scaled dtype is now: {X_test_scaled.dtype}\")\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Load the pre-trained Keras model ---\n",
        "keras_model = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
        "print(\"Keras model loaded successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Block 3: TFLite Model Conversions ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Block 3: TFLite Model Conversions ---\")\n",
        "\n",
        "# --- Strategy 1: Convert to INT8 with a larger representative dataset ---\n",
        "print(\"  [1/2] Converting to INT8...\")\n",
        "def representative_dataset_gen():\n",
        "    num_samples = min(1000, len(X_train_scaled))\n",
        "    for i in np.random.choice(len(X_train_scaled), num_samples, replace=False):\n",
        "        yield [X_train_scaled[i:i+1].astype(np.float32)]\n",
        "\n",
        "converter_int8 = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_int8.representative_dataset = representative_dataset_gen\n",
        "converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_int8.inference_input_type = tf.int8\n",
        "converter_int8.inference_output_type = tf.int8\n",
        "tflite_int8_model = converter_int8.convert()\n",
        "with open(TFLITE_INT8_PATH_DEST, 'wb') as f:\n",
        "    f.write(tflite_int8_model)\n",
        "print(f\"  INT8 model saved successfully.\")\n",
        "\n",
        "# --- Strategy 2: Convert to Float16 ---\n",
        "print(\"  [2/2] Converting to Float16...\")\n",
        "converter_float16 = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "converter_float16.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_float16.target_spec.supported_types = [tf.float16]\n",
        "tflite_float16_model = converter_float16.convert()\n",
        "with open(TFLITE_FLOAT16_PATH_DEST, 'wb') as f:\n",
        "    f.write(tflite_float16_model)\n",
        "print(f\"  Float16 model saved successfully.\")\n",
        "\n",
        "# --- Copy the JSON files to the new directory for a complete package ---\n",
        "shutil.copy(SCALER_PATH_JSON_SRC, SCALER_PATH_JSON_DEST)\n",
        "shutil.copy(LABELS_PATH_JSON_SRC, LABELS_PATH_JSON_DEST)\n",
        "print(\"  JSON assets copied to the new directory.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Block 4: Benchmarking and Final Report ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Block 4: Benchmarking and Final Report ---\")\n",
        "\n",
        "def benchmark_model(model_type, model_path=None, keras_model_instance=None):\n",
        "    \"\"\"Measures accuracy and inference speed for a given Keras or TFLite model.\"\"\"\n",
        "    print(f\"  Benchmarking {model_type} model...\")\n",
        "    # Keras Model\n",
        "    if model_type == 'Keras':\n",
        "        y_pred = np.argmax(keras_model_instance.predict(X_test_scaled, verbose=0), axis=1)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        latencies = []\n",
        "        for i in range(100):\n",
        "            if i >= 10: start_time = time.perf_counter()\n",
        "            _ = keras_model_instance.predict(X_test_scaled[i:i+1], verbose=0)\n",
        "            if i >= 10: latencies.append((time.perf_counter() - start_time) * 1000)\n",
        "        return accuracy, np.mean(latencies)\n",
        "\n",
        "    # TFLite Models\n",
        "    interpreter = tf.lite.Interpreter(model_path=str(model_path))\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()[0]\n",
        "    output_details = interpreter.get_output_details()[0]\n",
        "    y_pred = []\n",
        "    is_int8 = input_details['dtype'] == np.int8\n",
        "\n",
        "    for i in range(len(X_test_scaled)):\n",
        "        sample = X_test_scaled[i:i+1]\n",
        "        if is_int8:\n",
        "            scale, zero_point = input_details['quantization']\n",
        "            sample = (sample / scale + zero_point).astype(np.int8)\n",
        "        interpreter.set_tensor(input_details['index'], sample)\n",
        "        interpreter.invoke()\n",
        "        y_pred.append(np.argmax(interpreter.get_tensor(output_details['index'])[0]))\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    latencies = []\n",
        "    for i in range(100):\n",
        "        sample = X_test_scaled[i:i+1]\n",
        "        if is_int8:\n",
        "            scale, zero_point = input_details['quantization']\n",
        "            sample = (sample / scale + zero_point).astype(np.int8)\n",
        "        if i >= 10: start_time = time.perf_counter()\n",
        "        interpreter.set_tensor(input_details['index'], sample)\n",
        "        interpreter.invoke()\n",
        "        if i >= 10: latencies.append((time.perf_counter() - start_time) * 1000)\n",
        "    return accuracy, np.mean(latencies)\n",
        "\n",
        "# --- Run benchmarks ---\n",
        "keras_acc, keras_speed = benchmark_model('Keras', keras_model_instance=keras_model)\n",
        "int8_acc, int8_speed = benchmark_model('TFLite INT8', model_path=TFLITE_INT8_PATH_DEST)\n",
        "float16_acc, float16_speed = benchmark_model('TFLite Float16', model_path=TFLITE_FLOAT16_PATH_DEST)\n",
        "\n",
        "# --- Prepare and Print Final Report ---\n",
        "report_data = {\n",
        "    \"Model Type\": [\"Keras (Float32)\", \"TFLite (INT8)\", \"TFLite (Float16)\"],\n",
        "    \"Accuracy\": [f\"{keras_acc:.4f}\", f\"{int8_acc:.4f}\", f\"{float16_acc:.4f}\"],\n",
        "    \"Avg. Latency (ms)\": [f\"{keras_speed:.3f}\", f\"{int8_speed:.3f}\", f\"{float16_speed:.3f}\"],\n",
        "    \"Size (KB)\": [\n",
        "        f\"{os.path.getsize(KERAS_MODEL_PATH) / 1024:.1f}\",\n",
        "        f\"{os.path.getsize(TFLITE_INT8_PATH_DEST) / 1024:.1f}\",\n",
        "        f\"{os.path.getsize(TFLITE_FLOAT16_PATH_DEST) / 1024:.1f}\"\n",
        "    ]\n",
        "}\n",
        "report_df = pd.DataFrame(report_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"             MODEL OPTIMIZATION AND BENCHMARK REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(report_df.to_string(index=False))\n",
        "print(\"=\"*70)\n",
        "\n",
        "# --- Provide a final recommendation ---\n",
        "print(\"\\nRecommendation:\")\n",
        "if int8_acc >= 0.985 and int8_speed < float16_speed:\n",
        "    print(\"✅ The INT8 model is the clear winner. It maintains high accuracy while being the smallest and fastest.\")\n",
        "elif float16_acc > int8_acc + 0.01:\n",
        "     print(\"✅ The Float16 model is the recommended choice. It significantly improves accuracy over INT8, making it worth the slight size/speed trade-off.\")\n",
        "else:\n",
        "    print(\"⚠️ The INT8 model offers the best speed/size but has a noticeable accuracy drop. The Float16 model is a safer choice if accuracy is the top priority.\")\n",
        "    print(\"   For your Android app, test both to see which feels better in practice.\")\n",
        "\n",
        "print(\"\\nFinal deployable assets are located in:\")\n",
        "print(CONVERTED_ASSETS_DIR)\n",
        "!ls -lh {CONVERTED_ASSETS_DIR}"
      ]
    }
  ]
}